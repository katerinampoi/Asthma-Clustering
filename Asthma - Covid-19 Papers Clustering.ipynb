{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering asthma-related papers in CORD-19 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "In this project, we explore the relationship between asthma and coronaviruses. What are the most popular topics the research community is focuses on, before and after the COVID-19 outbreak? Are the areas of interest around asthma and coronaviruses the same before and after the appearance of SARS-CoV-2? The relationship between respiratory disorders and SARS-CoV-2 infection and has been broadly studied in a molecular, clinical and epidiomiological level, but remains still a controversial subject. More details about this relationship can be found here:\n",
    "\n",
    "In this project we cluster scientific publications in the topic of asthma and coronaviruses.Clustering is performed using NLP techniques and is based in the most frequent words apppering in the papers. Two groups of clusters are created, one for papers published before and one for papers published after the COVID-19 outbreak. For the two periods of times, clustering aims at identifying popular research topics and finding potential gaps in research between asthma and the new coronavirus.\n",
    "\n",
    "### Data\n",
    "In response to the COVID-19 pandemic a large database, the COVID-19 Open Research Dataset (CORD-19), was created and has been made publicly available. CORD-19 is a resource of hundreds of thousands scholarly articles, about COVID-19, SARS-CoV-2, and related coronaviruses.\n",
    "More information about this open source can be found here:\n",
    "https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data processing\n",
    "\n",
    "For this project, we select only those papers where the word \"asthma\" appears at least once in their abstract. This data is found in \"asthma_data\" csv file. In this analysis, we only consider papers written in English language. We take December 2019 as the point where papers about SARS-CoV-2 started to be published. According to this date, we divide our data as \"Before COVID-19\" and \"After COVID-19\" entries.The following analysis is then the same for these 2 groups of papers:\n",
    "\n",
    "Using Python's NLTK we perfom tokenization and then stemming of the papers' abstract text. With Scikit-learn’s Tfidf Vectorizer, tokens are transformed into to a matrix of TF-IDF features. These TF-IDF features are then catogorized into clusters with the use of Kmeans algorithm. Finally, the PCA algorithm is used for dimensionality reduction and vizualisation of clustering in a 2-dimensional space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.cluster import KMeans\n",
    "from langdetect import detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words(\"english\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_stop_words = ['whence', 'here', 'show', 'were', 'why', 'n’t', 'the', 'whereupon', 'not', 'more', 'how', 'eight', 'indeed', 'i', 'only', 'via', 'nine', 're', 'themselves', 'almost', 'to', 'already', 'front', 'least', 'becomes', 'thereby', 'doing', 'her', 'together', 'be', 'often', 'then', 'quite', 'less', 'many', 'they', 'ourselves', 'take', 'its', 'yours', 'each', 'would', 'may', 'namely', 'do', 'whose', 'whether', 'side', 'both', 'what', 'between', 'toward', 'our', 'whereby', \"'m\", 'formerly', 'myself', 'had', 'really', 'call', 'keep', \"'re\", 'hereupon', 'can', 'their', 'eleven', '’m', 'even', 'around', 'twenty', 'mostly', 'did', 'at', 'an', 'seems', 'serious', 'against', \"n't\", 'except', 'has', 'five', 'he', 'last', '‘ve', 'because', 'we', 'himself', 'yet', 'something', 'somehow', '‘m', 'towards', 'his', 'six', 'anywhere', 'us', '‘d', 'thru', 'thus', 'which', 'everything', 'become', 'herein', 'one', 'in', 'although', 'sometime', 'give', 'cannot', 'besides', 'across', 'noone', 'ever', 'that', 'over', 'among', 'during', 'however', 'when', 'sometimes', 'still', 'seemed', 'get', \"'ve\", 'him', 'with', 'part', 'beyond', 'everyone', 'same', 'this', 'latterly', 'no', 'regarding', 'elsewhere', 'others', 'moreover', 'else', 'back', 'alone', 'somewhere', 'are', 'will', 'beforehand', 'ten', 'very', 'most', 'three', 'former', '’re', 'otherwise', 'several', 'also', 'whatever', 'am', 'becoming', 'beside', '’s', 'nothing', 'some', 'since', 'thence', 'anyway', 'out', 'up', 'well', 'it', 'various', 'four', 'top', '‘s', 'than', 'under', 'might', 'could', 'by', 'too', 'and', 'whom', '‘ll', 'say', 'therefore', \"'s\", 'other', 'throughout', 'became', 'your', 'put', 'per', \"'ll\", 'fifteen', 'must', 'before', 'whenever', 'anyone', 'without', 'does', 'was', 'where', 'thereafter', \"'d\", 'another', 'yourselves', 'n‘t', 'see', 'go', 'wherever', 'just', 'seeming', 'hence', 'full', 'whereafter', 'bottom', 'whole', 'own', 'empty', 'due', 'behind', 'while', 'onto', 'wherein', 'off', 'again', 'a', 'two', 'above', 'therein', 'sixty', 'those', 'whereas', 'using', 'latter', 'used', 'my', 'herself', 'hers', 'or', 'neither', 'forty', 'thereupon', 'now', 'after', 'yourself', 'whither', 'rather', 'once', 'from', 'until', 'anything', 'few', 'into', 'such', 'being', 'make', 'mine', 'please', 'along', 'hundred', 'should', 'below', 'third', 'unless', 'upon', 'perhaps', 'ours', 'but', 'never', 'whoever', 'fifty', 'any', 'all', 'nobody', 'there', 'have', 'anyhow', 'of', 'seem', 'down', 'is', 'every', '’ll', 'much', 'none', 'further', 'me', 'who', 'nevertheless', 'about', 'everywhere', 'name', 'enough', '’d', 'next', 'meanwhile', 'though', 'through', 'on', 'first', 'been', 'hereby', 'if', 'move', 'so', 'either', 'amongst', 'for', 'twelve', 'nor', 'she', 'always', 'these', 'as', '’ve', 'amount', '‘re', 'someone', 'afterwards', 'you', 'nowhere', 'itself', 'done', 'hereafter', 'within', 'made', 'ca', 'them']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extending the list of stopwords taken into account\n",
    "stop_words.extend(spacy_stop_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gitcord_uid</th>\n",
       "      <th>sha</th>\n",
       "      <th>source_x</th>\n",
       "      <th>title</th>\n",
       "      <th>doi</th>\n",
       "      <th>pmcid</th>\n",
       "      <th>pubmed_id</th>\n",
       "      <th>license</th>\n",
       "      <th>abstract</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>...</th>\n",
       "      <th>journal</th>\n",
       "      <th>mag_id</th>\n",
       "      <th>who_covidence_id</th>\n",
       "      <th>arxiv_id</th>\n",
       "      <th>pdf_json_files</th>\n",
       "      <th>pmc_json_files</th>\n",
       "      <th>url</th>\n",
       "      <th>s2_id</th>\n",
       "      <th>abstract_lower</th>\n",
       "      <th>title_lower</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>qva0jt86</td>\n",
       "      <td>4ba79e54ecf81b30b56461a6aec2094eaf7b7f06</td>\n",
       "      <td>PMC</td>\n",
       "      <td>Relevance of human metapneumovirus in exacerba...</td>\n",
       "      <td>10.1186/1465-9921-6-150</td>\n",
       "      <td>PMC1334186</td>\n",
       "      <td>16371156.0</td>\n",
       "      <td>cc-by</td>\n",
       "      <td>BACKGROUND AND METHODS: Human metapneumovirus ...</td>\n",
       "      <td>2005-12-21</td>\n",
       "      <td>...</td>\n",
       "      <td>Respir Res</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>document_parses/pdf_json/4ba79e54ecf81b30b5646...</td>\n",
       "      <td>document_parses/pmc_json/PMC1334186.xml.json</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>background and methods: human metapneumovirus ...</td>\n",
       "      <td>relevance of human metapneumovirus in exacerba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chz8luni</td>\n",
       "      <td>d68d71553d3a31381c0c3851351f912a9a7be1c9</td>\n",
       "      <td>PMC</td>\n",
       "      <td>Surfactant therapy for acute respiratory failu...</td>\n",
       "      <td>10.1186/cc5944</td>\n",
       "      <td>PMC2206432</td>\n",
       "      <td>17573963.0</td>\n",
       "      <td>cc-by</td>\n",
       "      <td>INTRODUCTION: Exogenous surfactant is used to ...</td>\n",
       "      <td>2007-06-15</td>\n",
       "      <td>...</td>\n",
       "      <td>Crit Care</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>document_parses/pdf_json/d68d71553d3a31381c0c3...</td>\n",
       "      <td>document_parses/pmc_json/PMC2206432.xml.json</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>introduction: exogenous surfactant is used to ...</td>\n",
       "      <td>surfactant therapy for acute respiratory failu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3zh8jmc2</td>\n",
       "      <td>fe2000f280297c40bc53ce95d703a9ca6aac19fd</td>\n",
       "      <td>PMC</td>\n",
       "      <td>Differential Regulation of Type I Interferon a...</td>\n",
       "      <td>10.1371/journal.ppat.1000587</td>\n",
       "      <td>PMC2736567</td>\n",
       "      <td>19806178.0</td>\n",
       "      <td>cc-by</td>\n",
       "      <td>A number of paramyxoviruses are responsible fo...</td>\n",
       "      <td>2009-09-18</td>\n",
       "      <td>...</td>\n",
       "      <td>PLoS Pathog</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>document_parses/pdf_json/fe2000f280297c40bc53c...</td>\n",
       "      <td>document_parses/pmc_json/PMC2736567.xml.json</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a number of paramyxoviruses are responsible fo...</td>\n",
       "      <td>differential regulation of type i interferon a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7p3b6tyf</td>\n",
       "      <td>3ccbd07ee1865e4f2afffdb6cc8b6039ab605ee7</td>\n",
       "      <td>PMC</td>\n",
       "      <td>The Tennessee Children's Respiratory Initiativ...</td>\n",
       "      <td>10.1111/j.1440-1843.2010.01743.x</td>\n",
       "      <td>PMC2992986</td>\n",
       "      <td>20409023.0</td>\n",
       "      <td>no-cc</td>\n",
       "      <td>Background and objective: The ‘attack rate’ of...</td>\n",
       "      <td>2010-04-08</td>\n",
       "      <td>...</td>\n",
       "      <td>Respirology</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>document_parses/pdf_json/3ccbd07ee1865e4f2afff...</td>\n",
       "      <td>document_parses/pmc_json/PMC2992986.xml.json</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>background and objective: the ‘attack rate’ of...</td>\n",
       "      <td>the tennessee children's respiratory initiativ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>xrsyj1tc</td>\n",
       "      <td>fa88fbb8716e5fca7d513bcb5a0a608456a59205</td>\n",
       "      <td>PMC</td>\n",
       "      <td>Analysing the eosinophil cationic protein - a ...</td>\n",
       "      <td>10.1186/1465-9921-12-10</td>\n",
       "      <td>PMC3030543</td>\n",
       "      <td>21235798.0</td>\n",
       "      <td>cc-by</td>\n",
       "      <td>Eosinophil granulocytes reside in respiratory ...</td>\n",
       "      <td>2011-01-14</td>\n",
       "      <td>...</td>\n",
       "      <td>Respir Res</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>document_parses/pdf_json/fa88fbb8716e5fca7d513...</td>\n",
       "      <td>document_parses/pmc_json/PMC3030543.xml.json</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>eosinophil granulocytes reside in respiratory ...</td>\n",
       "      <td>analysing the eosinophil cationic protein - a ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  gitcord_uid                                       sha source_x  \\\n",
       "0    qva0jt86  4ba79e54ecf81b30b56461a6aec2094eaf7b7f06      PMC   \n",
       "1    chz8luni  d68d71553d3a31381c0c3851351f912a9a7be1c9      PMC   \n",
       "2    3zh8jmc2  fe2000f280297c40bc53ce95d703a9ca6aac19fd      PMC   \n",
       "3    7p3b6tyf  3ccbd07ee1865e4f2afffdb6cc8b6039ab605ee7      PMC   \n",
       "4    xrsyj1tc  fa88fbb8716e5fca7d513bcb5a0a608456a59205      PMC   \n",
       "\n",
       "                                               title  \\\n",
       "0  Relevance of human metapneumovirus in exacerba...   \n",
       "1  Surfactant therapy for acute respiratory failu...   \n",
       "2  Differential Regulation of Type I Interferon a...   \n",
       "3  The Tennessee Children's Respiratory Initiativ...   \n",
       "4  Analysing the eosinophil cationic protein - a ...   \n",
       "\n",
       "                                doi       pmcid   pubmed_id license  \\\n",
       "0           10.1186/1465-9921-6-150  PMC1334186  16371156.0   cc-by   \n",
       "1                    10.1186/cc5944  PMC2206432  17573963.0   cc-by   \n",
       "2      10.1371/journal.ppat.1000587  PMC2736567  19806178.0   cc-by   \n",
       "3  10.1111/j.1440-1843.2010.01743.x  PMC2992986  20409023.0   no-cc   \n",
       "4           10.1186/1465-9921-12-10  PMC3030543  21235798.0   cc-by   \n",
       "\n",
       "                                            abstract publish_time  ...  \\\n",
       "0  BACKGROUND AND METHODS: Human metapneumovirus ...   2005-12-21  ...   \n",
       "1  INTRODUCTION: Exogenous surfactant is used to ...   2007-06-15  ...   \n",
       "2  A number of paramyxoviruses are responsible fo...   2009-09-18  ...   \n",
       "3  Background and objective: The ‘attack rate’ of...   2010-04-08  ...   \n",
       "4  Eosinophil granulocytes reside in respiratory ...   2011-01-14  ...   \n",
       "\n",
       "       journal mag_id  who_covidence_id arxiv_id  \\\n",
       "0   Respir Res    NaN               NaN      NaN   \n",
       "1    Crit Care    NaN               NaN      NaN   \n",
       "2  PLoS Pathog    NaN               NaN      NaN   \n",
       "3  Respirology    NaN               NaN      NaN   \n",
       "4   Respir Res    NaN               NaN      NaN   \n",
       "\n",
       "                                      pdf_json_files  \\\n",
       "0  document_parses/pdf_json/4ba79e54ecf81b30b5646...   \n",
       "1  document_parses/pdf_json/d68d71553d3a31381c0c3...   \n",
       "2  document_parses/pdf_json/fe2000f280297c40bc53c...   \n",
       "3  document_parses/pdf_json/3ccbd07ee1865e4f2afff...   \n",
       "4  document_parses/pdf_json/fa88fbb8716e5fca7d513...   \n",
       "\n",
       "                                 pmc_json_files  \\\n",
       "0  document_parses/pmc_json/PMC1334186.xml.json   \n",
       "1  document_parses/pmc_json/PMC2206432.xml.json   \n",
       "2  document_parses/pmc_json/PMC2736567.xml.json   \n",
       "3  document_parses/pmc_json/PMC2992986.xml.json   \n",
       "4  document_parses/pmc_json/PMC3030543.xml.json   \n",
       "\n",
       "                                                 url s2_id  \\\n",
       "0  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1...   NaN   \n",
       "1  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2...   NaN   \n",
       "2  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2...   NaN   \n",
       "3  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2...   NaN   \n",
       "4  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3...   NaN   \n",
       "\n",
       "                                      abstract_lower  \\\n",
       "0  background and methods: human metapneumovirus ...   \n",
       "1  introduction: exogenous surfactant is used to ...   \n",
       "2  a number of paramyxoviruses are responsible fo...   \n",
       "3  background and objective: the ‘attack rate’ of...   \n",
       "4  eosinophil granulocytes reside in respiratory ...   \n",
       "\n",
       "                                         title_lower  \n",
       "0  relevance of human metapneumovirus in exacerba...  \n",
       "1  surfactant therapy for acute respiratory failu...  \n",
       "2  differential regulation of type i interferon a...  \n",
       "3  the tennessee children's respiratory initiativ...  \n",
       "4  analysing the eosinophil cationic protein - a ...  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We load the csv file to pands dataframe and have a look at the papers' metadata we'll use\n",
    "asthma_df = pd.read_csv(\"asthma_data.csv\")\n",
    "asthma_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 2567 papers containing the word \"asthma\", among the coronavirus-related publications "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2567, 21)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asthma_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the langdetect google library to dect the language of the \"abstract\" column in our dataframe\n",
    "\n",
    "asthma_df[\"lang_detect\"] = asthma_df[\"abstract\"].apply(detect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As non-english papers are a small percent of our total papers, weexclude them from our analysis\n",
    "\n",
    "asthma_df[\"lang_detect\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have 2528 papers in total, written in english."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asthma_df = asthma_df.loc[asthma_df['lang_detect'] == \"en\"]\n",
    "asthma_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asthma_df['source_x'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We divide the papers between those published before the new coronavirus SARS-CoV-2 has appeared and those published after the COVID-19 outbreak. We pick December 2019 as the cut-off date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asthma_before_covid = asthma_df.loc[asthma_df['publish_time']<\"2019-12-01\"].reset_index(drop=True)\n",
    "asthma_after_covid = asthma_df.loc[asthma_df['publish_time']>=\"2019-12-01\"].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also have a look at the number of the papers published by month, since the covid outbreak. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asthma_after_covid['publish_time_new'] =  pd.to_datetime(asthma_after_covid['publish_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asthma_after_covid['publish_month_year'] = pd.to_datetime(asthma_after_covid['publish_time']).dt.to_period('M')\n",
    "asthma_after_covid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asthma_after_covid = asthma_after_covid.sort_values('publish_month_year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = asthma_after_covid[\"publish_month_year\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_df = dates.to_frame().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_df = dates_df.sort_values(\"index\")\n",
    "dates_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph below illustrates the number of papers published through the last 12-14 months. However, we recognize that the two picks noticed in January 2020 and January 2021 are not completely accurate. As an amount of papers had only the year (yyyy) mentioned in their publication date, their publivcation date is taken as 01/01/yyyy.\n",
    "\n",
    "As a result, we cannot draw a very accurate example of the distribution of publications through the months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_df.plot(x ='index', y = 'publish_month_year')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_before = asthma_before_covid[\"abstract_lower\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_tokenizer(str_input):\n",
    "    \n",
    "    stemmer = PorterStemmer()\n",
    "    words = nltk.word_tokenize(str_input)\n",
    "    words = [word for word in words if word.lower() not in stop_words]\n",
    "\n",
    "    words = [word.replace('â¡', '') for word in words]\n",
    "    words = [word.replace('â¢', '') for word in words]\n",
    "    words = [word.replace('â£', '') for word in words]\n",
    "    \n",
    "    words = [''.join(c for c in word if c not in string.punctuation+'©±×≤≥●＜--“”→„') for word in words]\n",
    "    words = [word for word in words if word not in ['‘', '’', '„']]\n",
    "        \n",
    "    words = [word for word in words if word]\n",
    "    words = [word for word in words if not any(char.isdigit() for char in word)]\n",
    "    \n",
    "    words = [stemmer.stem(word) for word in words]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_tokenizer(string_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_before = TfidfVectorizer(min_df=5,tokenizer=custom_tokenizer,\n",
    "                             max_features=2000,\n",
    "                      stop_words='english')\n",
    "matrix_before = vec_before.fit_transform(texts_before)\n",
    "df_before = pd.DataFrame(matrix_before.toarray(), columns=vec_before.get_feature_names())\n",
    "df_before.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information about the useof Kmeans in clustering: https://towardsdatascience.com/understanding-k-means-clustering-in-machine-learning-6a6e67336aa1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_clusters=10\n",
    "km_before = KMeans(n_clusters=number_of_clusters)\n",
    "km_before.fit(matrix_before)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have an over view of our cluster's centers (centroids) and labels. After that, we get the top terms for every cluster. In other words, we see which are the most frequently mentioned words per cluster. Note: since we have used Stemming, we only have the root of the words now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids_before, labels_before = km_before.cluster_centers_, km_before.labels_\n",
    "print(centroids_before)\n",
    "print(labels_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Top terms per cluster:\")\n",
    "order_centroids_before = km_before.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vec_before.get_feature_names()\n",
    "for i in range(number_of_clusters):\n",
    "    top_ten_words = [terms[ind] for ind in order_centroids_before[i, :20]]\n",
    "    print(\"Cluster {}: {}\".format(i, ' '.join(top_ten_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_centroids_before\n",
    "#word with index 1049 has highest Tfidf value in the first array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information about PCA and its implementation in Python:\n",
    "https://jakevdp.github.io/PythonDataScienceHandbook/05.09-principal-component-analysis.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = preprocessing.Normalizer().fit_transform(df_before)\n",
    "# Dimesionality reduction to 2\n",
    "pca_model = PCA(n_components=2, random_state = 2)\n",
    "pca_model.fit(T) \n",
    "T = pca_model.transform(T) \n",
    "\n",
    "# transform the 'centroids of KMeans'\n",
    "\n",
    "centroid_pca = pca_model.transform(centroids_before)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asthma_before_covid['labels'] = km_before.labels_\n",
    "asthma_before_covid['pca_1'] = T[:, 0]\n",
    "asthma_before_covid['pca_2'] = T[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asthma_before_covid['labels'] = asthma_before_covid['labels'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(asthma_before_covid, \n",
    "                 x=\"pca_1\", \n",
    "                 y=\"pca_2\", \n",
    "                 color=\"labels\",\n",
    "                 hover_data=['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After covid-19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_after = asthma_after_covid[\"abstract_lower\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_after = TfidfVectorizer(tokenizer=custom_tokenizer,\n",
    "                      stop_words='english', \n",
    "                           max_features=1000)\n",
    "matrix_after = vec_after.fit_transform(texts_after)\n",
    "df_after = pd.DataFrame(matrix_after.toarray(), columns=vec_after.get_feature_names())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_after.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_clusters=10\n",
    "km_after = KMeans(n_clusters=number_of_clusters)\n",
    "km_after.fit(matrix_after)\n",
    "km_after.fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids_after, labels_after = km_after.cluster_centers_, km_after.labels_\n",
    "print(centroids_after)\n",
    "print(labels_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Top terms per cluster:\")\n",
    "order_centroids_after = km_after.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vec_after.get_feature_names()\n",
    "for i in range(number_of_clusters):\n",
    "    top_ten_words = [terms[ind] for ind in order_centroids_after[i, :20]]\n",
    "    print(\"Cluster {}: {}\".format(i, ' '.join(top_ten_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_centroids_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_after = preprocessing.Normalizer().fit_transform(df_after)\n",
    "# Dimesionality reduction to 2\n",
    "pca_model = PCA(n_components=2, random_state=0)\n",
    "pca_model.fit(T_after) \n",
    "T_after = pca_model.transform(T_after) \n",
    "\n",
    "centroid_pca_after = pca_model.transform(centroids_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asthma_after_covid['labels'] = km_after.labels_\n",
    "asthma_after_covid['pca_1'] = T_after[:, 0]\n",
    "asthma_after_covid['pca_2'] = T_after[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asthma_after_covid['labels'] = asthma_after_covid['labels'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(asthma_after_covid, \n",
    "                 x=\"pca_1\", \n",
    "                 y=\"pca_2\", \n",
    "                 color=\"labels\",\n",
    "                 hover_data=['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
